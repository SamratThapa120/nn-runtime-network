{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/app/nn-runtime-network/notebooks/hopleninfo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['path', 'split', 'config_type', 'modeltype', 'graphtype', 'modelname',\n",
       "       'config_nodes', 'nodes', 'edges', 'config_runtime', 'percent of config',\n",
       "       'ratio of config nodes', 'ratio of config nodes @ hop 0',\n",
       "       'ratio of config nodes @ hop 1', 'ratio of config nodes @ hop 2',\n",
       "       'ratio of config nodes @ hop 3', 'ratio of config nodes @ hop 4',\n",
       "       'ratio of config nodes @ hop 5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43615"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"nodes\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name:1 9294.0\n",
      "name:2 14124.0\n",
      "name:3 21690.0\n",
      "name:4 32679.0\n",
      "name:5 39501.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,6):\n",
    "    print(f\"name:{i}\",(df[f\"ratio of config nodes @ hop {i}\"]*df[\"nodes\"]).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample JSON data\n",
    "data = json.load(open(\"/app/nn-runtime-network/workdir/listmle_graphsage_fused_xla_embedding/node_conf_importances_group.json\"))\n",
    "data2 = json.load(open(\"/app/nn-runtime-network/workdir/listmle_graphsage_fused_xla_embedding/node_importances_group.json\"))\n",
    "data.update(data2)\n",
    "\n",
    "# Extracting Kendall tau values and labels\n",
    "kendall_tau_data = {}\n",
    "original_kendall_tau = None\n",
    "\n",
    "for key, value in data.items():\n",
    "    if key == \"original\":\n",
    "        original_kendall_tau = value[1]\n",
    "    else:\n",
    "        kendall_tau_data[key] = value[1]\n",
    "\n",
    "# Sort the keys by their ktau values and select the top 10\n",
    "top_10_keys = sorted(kendall_tau_data, key=kendall_tau_data.get)[:13]\n",
    "top_10_ktaus = [kendall_tau_data[key] for key in top_10_keys]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "bar_plot = plt.bar([\"_\".join(x.split(\"_\")[:-1]) for x in  top_10_keys], top_10_ktaus, color='skyblue')\n",
    "\n",
    "# Adding the baseline (original value)\n",
    "plt.axhline(y=original_kendall_tau, color='r', linestyle='-', label='Original Baseline')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Feature groups')\n",
    "plt.ylabel('Kendall Tau')\n",
    "plt.title('Performance Change when Feature (Groups) are Corrupted')\n",
    "\n",
    "# Rotate the x-axis labels\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Adding a legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.listmle_gsage_xla_fused import Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = Configs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG.load_state_dict(os.path.join(CFG.OUTPUTDIR,\"bestmodel_opa.pkl\"),map_location=\"cpu\")\n",
    "model = CFG.model\n",
    "model.cuda()\n",
    "model.eval()\n",
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def parse_file_to_dicts(file_path):\n",
    "    dicts = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.startswith('###Iter:'):\n",
    "                # Extract the JSON string part\n",
    "                json_str = line.split('  ::  ', 1)[1].strip()\n",
    "                iter = int(line.split('  ::  ', 1)[0].strip().split(\"###Iter: \")[1])\n",
    "\n",
    "                # Use json.loads to convert the string to a dictionary\n",
    "                dict_data = json.loads(json_str.replace(\"'\", \"\\\"\"))\n",
    "                dict_data[\"iteration\"] = iter\n",
    "                dicts.append(dict_data)\n",
    "    return dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_info = {}\n",
    "for i in sorted(glob.glob(\"/app/nn-runtime-network/workdir/listmle*/logs.txt\")):\n",
    "    training_dicts = parse_file_to_dicts(os.path.join(i))\n",
    "    training_info[i.split(\"/\")[4]] = training_dicts\n",
    "    maxim = -1\n",
    "    tmpdict = {}\n",
    "    for d in training_dicts:\n",
    "        if d.get(\"ordered_pair_accuracy\",False):\n",
    "            val = d.get(\"ordered_pair_accuracy\")\n",
    "            if val>maxim:\n",
    "                maxim=val\n",
    "                tmpdict =d\n",
    "    print(i.split(\"/\")[4],\":\",tmpdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['default:nlp','default+random:xla','random:nlp','random:xla']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "datasets = [\n",
    "    ['listmle_graphsage_default_nlp', 'listmle_graphsage_fused_xla_embedding', 'listmle_graphsage_random_nlp_embedding_redo', \"listmle_graphsage_random_xla_embedding\"],\n",
    "]\n",
    "num_rows = len(datasets)\n",
    "num_cols = len(datasets[0])\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    fig, axs = plt.subplots(num_rows, num_cols, figsize=(24, 6 * 1))\n",
    "\n",
    "    for j, k in enumerate(dataset):\n",
    "        ax = axs[i, j] if num_rows > 1 else axs[j]\n",
    "\n",
    "        iters = [x[\"iteration\"] for x in training_info[k] if \"training_loss\" in x and \"valid_loss\" in x]\n",
    "        valid_loss = [x[\"valid_loss\"]/200 for x in training_info[k] if \"training_loss\" in x and \"valid_loss\" in x]\n",
    "        training_loss = [x[\"training_loss\"]/10 for x in training_info[k] if \"training_loss\" in x and \"valid_loss\" in x]\n",
    "        opa = [x[\"ordered_pair_accuracy\"] for x in training_info[k] if \"training_loss\" in x and \"valid_loss\" in x]\n",
    "        ktau = [x[\"kendall_tau\"] for x in training_info[k] if \"training_loss\" in x and \"valid_loss\" in x]\n",
    "\n",
    "        # Ensure the lengths are equal\n",
    "        assert len(iters) == len(valid_loss) == len(training_loss) == len(opa)\n",
    "\n",
    "        ax.plot(iters, valid_loss, label='Valid Loss/200')\n",
    "        ax.plot(iters, training_loss, label='Training Loss/10', linestyle='--')\n",
    "        ax.plot(iters, opa, label='OPA', linestyle=':')\n",
    "        ax.plot(iters, ktau, label='kendall tau', linestyle='-.')\n",
    "\n",
    "        ax.set_xlabel('Iterations')\n",
    "        ax.set_ylabel('Loss')\n",
    "        ax.set_title(names[j])\n",
    "        ax.legend()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dicts = parse_file_to_dicts(os.path.join(CFG.OUTPUTDIR,\"logs.txt\"))\n",
    "maxim = -1\n",
    "tmpdict = {}\n",
    "for d in training_dicts:\n",
    "    if d.get(\"ordered_pair_accuracy\",False):\n",
    "        val = d.get(\"ordered_pair_accuracy\")\n",
    "        if val>maxim:\n",
    "            maxim=val\n",
    "            tmpdict =d\n",
    "tmpdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total_params, trainable_params\n",
    "\n",
    "total, trainable = count_parameters(model)\n",
    "print(f\"Total parameters: {total}\")\n",
    "print(f\"Trainable parameters: {trainable}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in glob.glob(\"../configs/listmle*.py\"):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CFG.test_dataset.files = CFG.test_dataset.files[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USED_KEYS = [\"node_features\",\"node_config_features\",\"node_separation\",\"node_ops\",\"edges\",\"batches\"]\n",
    "pred_sequences = []\n",
    "for info in tqdm(CFG.test_dataset):\n",
    "    predictions = []\n",
    "    for batch in CFG.stream_dataloder_collate([info]):\n",
    "        with torch.no_grad():\n",
    "            out = model(**{k:batch[k].cuda() for k in USED_KEYS}).cpu()\n",
    "            predictions.append(out)\n",
    "    pred_sequences.append(torch.concat(predictions).flatten()[:len(info[\"config_runtimes\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(CFG.test_dataset.files,columns=[\"ID\"])\n",
    "if CFG.test_dataset.is_tile:\n",
    "    df[\"ID\"] = df.ID.apply(lambda x: x.split(\"/\")[-1].split(\".\")[0].replace(\"___\",\":\").replace(\"test:\",\"\"))\n",
    "    df[\"TopConfigs\"] = [\";\".join([str(x) for x in ps.numpy().argsort().tolist()[:10]]) for ps in pred_sequences]\n",
    "else:\n",
    "    df[\"ID\"] = df.ID.apply(lambda x: \"layout:\"+x.split(\"/\")[-1].split(\".\")[0].replace(\"___\",\":\").replace(\"test:\",\"\"))\n",
    "    df[\"TopConfigs\"] = [\";\".join([str(x) for x in ps.numpy().argsort().tolist()]) for ps in pred_sequences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(CFG.OUTPUTDIR,\"submission.csv\"),index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine multiple files and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    \"/app/nn-runtime-network/workdir/listmle_graphsage_default_nlp_embedding_hop2/submission.csv\",\n",
    "    \"/app/nn-runtime-network/workdir/listmle_graphsage_fused_xla_embedding_hop2/submission.csv\",\n",
    "    '/app/nn-runtime-network/workdir/listmle_graphsage_random_nlp_embedding_hop2/submission.csv',\n",
    "    \"/app/nn-runtime-network/workdir/listmle_graphsage_random_xla_embedding_hop2/submission.csv\",\n",
    "    \"/app/nn-runtime-network/workdir/tile_model/results_1697250122338.csv\"\n",
    "\n",
    "]\n",
    "make_zero = [\n",
    "    False,False,False,False,False\n",
    "]\n",
    "# make_zero = [\n",
    "#     True,True,True,True,True\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfs =[]\n",
    "for x,mask in zip(files,make_zero):\n",
    "    tdf = pd.read_csv(x)\n",
    "    if \"fused\" in x:\n",
    "        tdf = tdf[tdf.ID.apply(lambda x: \"default\" in x)]\n",
    "    if mask:\n",
    "        print(\"skipping\")\n",
    "        tdf[\"TopConfigs\"] = \"0;1\"\n",
    "    pdfs.append(tdf.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdfs = pd.concat(pdfs).drop_duplicates().reset_index(drop=True)\n",
    "name=\"submission_embedding_hop2.csv\"\n",
    "if not os.path.exists(os.path.join(\"./submission\",name)):\n",
    "    tdfs.to_csv(os.path.join(\"./submission\",name),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
